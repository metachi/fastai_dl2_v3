{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 8 - Part 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a reimplementation of fastai part 2 version 3 in Swift.\n",
    "https://github.com/fastai/fastai_docs/blob/master/dev_course/dl2/02_fully_connected.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: this requires my fork of [swift-jupyter](https://github.com/metachi/swift-jupyter) and a clone of my [TimeMagic](https://github.com/metachi/TimeMagic) repo for the ```%%time``` and ```%%timeit``` magic commands to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(path: \"~/gitrepos/TimeMagic\")\n",
      "\t\tTimeMagic\n",
      "\t.package(url: \"https://github.com/mxcl/Path.swift\", from: \"0.16.1\")\n",
      "\t\tPath\n",
      "\t.package(url: \"https://github.com/JustHTTP/Just\", from: \"0.7.1\")\n",
      "\t\tJust\n",
      "Fetching https://github.com/mxcl/Path.swift\n",
      "Fetching https://github.com/JustHTTP/Just\n",
      "Completed resolution in 1.36s\n",
      "Cloning https://github.com/mxcl/Path.swift\n",
      "Resolving https://github.com/mxcl/Path.swift at 0.16.2\n",
      "Cloning https://github.com/JustHTTP/Just\n",
      "Resolving https://github.com/JustHTTP/Just at 0.7.1\n",
      "Compile Swift Module 'TimeMagic' (1 sources)\n",
      "Compile Swift Module 'Just' (1 sources)\n",
      "Compile Swift Module 'Path' (9 sources)\n",
      "Compile Swift Module 'jupyterInstalledPackages' (1 sources)\n",
      "Linking ./.build/x86_64-unknown-linux/debug/libjupyterInstalledPackages.so\n",
      "Installation complete!"
     ]
    }
   ],
   "source": [
    "%install '.package(path: \"~/gitrepos/TimeMagic\")' TimeMagic\n",
    "%install '.package(url: \"https://github.com/mxcl/Path.swift\", from: \"0.16.1\")' Path\n",
    "%install '.package(url: \"https://github.com/JustHTTP/Just\", from: \"0.7.1\")' Just"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TimeMagic\n",
    "import Foundation\n",
    "import Path\n",
    "import Just"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jeff/.fastai/data/test.txt\r\n"
     ]
    }
   ],
   "source": [
    "print(Path.home/\".fastai\"/\"data\"/\"test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "public func download(_ url: String, dest: String){\n",
    "    let r = Just.get(url, allowRedirects:false)\n",
    "    do {\n",
    "        try r.content!.write(to: URL.init(fileURLWithPath: dest))\n",
    "    } catch {\n",
    "        print(\"error downloading \\(url)\")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "let base = \"http://yann.lecun.com/exdb/mnist/\"\n",
    "let trn_imgs = \"train-images-idx3-ubyte\"\n",
    "let trn_lbls = \"train-labels-idx1-ubyte\"\n",
    "let val_imgs = \"t10k-images-idx3-ubyte\"\n",
    "let val_lbls = \"t10k-labels-idx1-ubyte\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "let dest = Path.home/\".fastai\"/\"data\"/\"mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if !dest.exists{\n",
    "    dest.mkdir()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileName in [trn_imgs, trn_lbls, val_imgs, val_lbls] {\n",
    "    var destPath = dest/(fileName)\n",
    "    if !destPath.exists{\n",
    "        download(\"\\(base)/\\(fileName)\", dest: destPath.string + \".gz\")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jeff/.fastai/data/mnist/t10k-labels-idx1-ubyte\r\n",
      "/home/jeff/.fastai/data/mnist/train-labels-idx1-ubyte\r\n",
      "/home/jeff/.fastai/data/mnist/train-images-idx3-ubyte\r\n",
      "/home/jeff/.fastai/data/mnist/t10k-images-idx3-ubyte\r\n"
     ]
    }
   ],
   "source": [
    "for n in dest.ls() {\n",
    "    print(n.path)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gunzip the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jeff/.fastai/data/mnist/t10k-labels-idx1-ubyte\r\n",
      "/home/jeff/.fastai/data/mnist/train-labels-idx1-ubyte\r\n",
      "/home/jeff/.fastai/data/mnist/train-images-idx3-ubyte\r\n",
      "/home/jeff/.fastai/data/mnist/t10k-images-idx3-ubyte\r\n"
     ]
    }
   ],
   "source": [
    "for n in dest.ls() {\n",
    "    print(n.path)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [Yann Lecunn's site](http://yann.lecun.com/exdb/mnist/) for info on why we have to drop the first few k bits.  See the \"TRAINING SET LABEL FILE\" heading and similarly named headings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "func loadData(path: String, shape: [Int32], is_label: Bool) -> Tensor<Float> {\n",
    "    let dropK: Int = (is_label ? 8 : 16)\n",
    "    let data = try! Data.init(contentsOf: \n",
    "                     URL.init(fileURLWithPath: path)\n",
    "                    ).dropFirst(dropK)\n",
    "    let tensorShape = TensorShape.init(shape)\n",
    "    return Tensor(data.map(Float.init)).reshaped(to: tensorShape)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var xTrain: Tensor<Float> = loadData(path: (dest/trn_imgs).string,\n",
    "                   shape: [60000, 784],\n",
    "                   is_label: false)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "let yTrain: Tensor<Float> = loadData(path: (dest/trn_lbls).string,\n",
    "                   shape: [60000],\n",
    "                   is_label: true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "var xValid: Tensor<Float> = loadData(path: (dest/val_imgs).string,\n",
    "                   shape: [10000, 784],\n",
    "                   is_label: false)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "let yValid: Tensor<Float> = loadData(path: (dest/val_lbls).string,\n",
    "                   shape: [10000],\n",
    "                   is_label: true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The forward and backward passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "public extension Tensor where Scalar : FloatingPoint {\n",
    "    func stddev(alongAxes axes: [Int32])-> Tensor<Scalar>{\n",
    "        let mean = self.mean(alongAxes: axes)\n",
    "        return sqrt((self - mean).squared().mean(alongAxes: axes))\n",
    "    }\n",
    "    \n",
    "    func stddev()-> Tensor<Scalar>{\n",
    "        let mean = self.mean()\n",
    "        return sqrt((self - mean).squared().mean())\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "func normalize<Scalar: FloatingPoint>(_ x: Tensor<Scalar>, _ mean: Tensor<Scalar>? = nil, _ stddev: Tensor<Scalar>? = nil) ->  Tensor<Scalar>{\n",
    "    var mean = (mean ?? x.mean())\n",
    "    var stddev = (stddev ?? x.stddev())\n",
    "    return (x-mean)/stddev\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "var xTrainNormal: Tensor<Float> = normalize(xTrain)\n",
    "var xValidNormal: Tensor<Float> = normalize(xValid,\n",
    "                                            xTrain.mean(),\n",
    "                                            sqrt(xTrain.variance(alongAxes: [0,1]))\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "func almostEqual<Scalar: SignedNumeric & FloatingPoint>(_ x: Tensor<Scalar>, _ y: Tensor<Scalar>, _ tolerance: Tensor<Scalar>) -> Bool{\n",
    "    return (abs(x - y) .< tolerance).all()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4449139e-08 [[1.0000017]]\r\n"
     ]
    }
   ],
   "source": [
    "print(xTrainNormal.mean(), xTrainNormal.variance(alongAxes: [0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "almostEqual(xTrainNormal.mean(), Tensor(0), Tensor(1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "almostEqual(sqrt(xTrainNormal.variance(alongAxes: [0,1])),\n",
    "            Tensor(1),\n",
    "            Tensor(1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be near 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0060177604 [[1.0154601]]\r\n"
     ]
    }
   ],
   "source": [
    "print(xValidNormal.mean(), xValidNormal.variance(alongAxes: [0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "almostEqual(xValidNormal.mean(), Tensor(0), Tensor(1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "almostEqual(sqrt(xValidNormal.variance(alongAxes: [0,1])),\n",
    "            Tensor(1),\n",
    "            Tensor(1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 784 10.0\r\n"
     ]
    }
   ],
   "source": [
    "var shp = xTrainNormal.shape\n",
    "let n = shp[0]\n",
    "let m = shp[1]\n",
    "let c = yTrain.max() + 1\n",
    "print(n, m, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foundations version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "var nh: Int32 = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "public extension Tensor where Scalar : BinaryFloatingPoint {\n",
    "    init(simpleKaiming shape: TensorShape){\n",
    "        self.init(Tensor(randomNormal: shape) / sqrt(Scalar(shape[0])))\n",
    "    }\n",
    "    \n",
    "    init(kaiming shape: TensorShape){\n",
    "        self.init(Tensor(randomNormal: shape) * sqrt(2/Scalar(shape[0])))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "// kaiming init / he init\n",
    "var w1 = Tensor<Float>(simpleKaiming: [m, nh])\n",
    "var b1 = Tensor<Float>(zeros: [nh])\n",
    "var w2 = Tensor<Float>(simpleKaiming: [nh, 1])\n",
    "var b2 = Tensor<Float>(zeros: [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "func linear<Scalar: TensorFlowFloatingPoint>(_ x: Tensor<Scalar>, _ w: Tensor<Scalar>, _ b: Tensor<Scalar>) -> Tensor<Scalar>{\n",
    "    return matmul(x, w) + b\n",
    "}\n",
    "\n",
    "@differentiating(linear)\n",
    "func linearDerivative<Scalar: TensorFlowFloatingPoint>(_ x: Tensor<Scalar>, _ w: Tensor<Scalar>, _ b: Tensor<Scalar>) -> (value: Tensor<Scalar>, pullback: (Tensor<Scalar>) -> (Tensor<Scalar>, Tensor<Scalar>, Tensor<Scalar>)){\n",
    "    let out = Tensor<Scalar>(linear(x, w, b))\n",
    "    return (value: out, pullback: {v in (matmul(v, w.transposed()), matmul(x.transposed(), v), v.sum(squeezingAxes: 0))})\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ 3 elements\n",
       "  - .0 : [[2.0, 2.0]]\n",
       "  - .1 : [[3.0, 3.0], [3.0, 3.0]]\n",
       "  - .2 : [1.0, 1.0]\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//just a quick gutcheck\n",
    "pullback(at: Tensor([[3.0, 3.0]]), Tensor([[1.0, 1.0], [1.0, 1.0]]), Tensor([1.0, 1.0]), in: linear)(Tensor([[1.0, 1.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0]\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//just a quick gutcheck\n",
    "pullback(at: Tensor([-3.0, 3.0]), in: relu)(Tensor([1.0, 1.0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "// there is already a relu function in s4tf\n",
    "func myRelu<Scalar: Numeric & Comparable>(_ x: Tensor<Scalar>) -> Tensor<Scalar> {\n",
    "    return max(0, x)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "var t = linear(xValidNormal, w1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1326691 1.022629\r\n"
     ]
    }
   ],
   "source": [
    "print(t.mean(), t.stddev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "var t = myRelu(linear(xValidNormal, w1, b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.471653 0.6623134\r\n"
     ]
    }
   ],
   "source": [
    "print(t.mean(), t.stddev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "var w1 = Tensor<Float>(kaiming: [m, nh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00034631704 0.0504034\r\n"
     ]
    }
   ],
   "source": [
    "print(w1.mean(), w1.stddev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "var t = myRelu(linear(xValidNormal, w1, b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.52433354 0.8077385\r\n"
     ]
    }
   ],
   "source": [
    "print(t.mean(), t.stddev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "// there is already a relu function in s4tf\n",
    "func myRelu<Scalar: BinaryFloatingPoint & Comparable>(_ x: Tensor<Scalar>) -> Tensor<Scalar> {\n",
    "    return max(0, x) - 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009324098 0.7946501\r\n"
     ]
    }
   ],
   "source": [
    "var w1 = Tensor<Float>(kaiming: [m, nh])\n",
    "var t1 = myRelu(linear(xValidNormal, w1, b1))\n",
    "print(t1.mean(), t1.stddev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "func myModel<Scalar: TensorFlowFloatingPoint>(_ x: Tensor<Scalar>,\n",
    "             _ wt1: Tensor<Scalar>,\n",
    "             _ bias1: Tensor<Scalar>,\n",
    "             _ wt2: Tensor<Scalar>,\n",
    "             _ bias2: Tensor<Scalar>) -> Tensor<Scalar> {\n",
    "    let l1: Tensor<Scalar> = linear(x, wt1, bias1)\n",
    "    let l2: Tensor<Scalar> = relu(l1)\n",
    "    let l3: Tensor<Scalar> = linear(l2, wt2, bias2)\n",
    "    return l3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 404.592 µs\r\n",
      "Min: 302.016 µs\r\n",
      "Mean: 360.37352000000004 µs\r\n",
      "Std Dev: 21.900115580736102 µs\r\n"
     ]
    }
   ],
   "source": [
    "%%timeit 100\n",
    "var _ = myModel(xValidNormal, w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function: MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "func mse<Scalar: TensorFlowFloatingPoint>(_ pred: Tensor<Scalar>, _ target: Tensor<Scalar>)->Tensor<Scalar>{\n",
    "    return (pred.squeezingShape(at: -1) - target).squared().mean()\n",
    "}\n",
    "\n",
    "@differentiating(mse)\n",
    "func mseDerivative<Scalar: TensorFlowFloatingPoint>(_ pred: Tensor<Scalar>, _ target: Tensor<Scalar>) -> (value: Tensor<Scalar>, pullback: (Tensor<Scalar>) -> (Tensor<Scalar>, Tensor<Scalar>)){\n",
    "    let out: Tensor<Scalar> = mse(pred, target)\n",
    "    let dPred: Tensor<Scalar> = 2.0 * (pred.squeezingShape(at: -1) - target).expandingShape(at: -1) / Tensor<Scalar>(pred.shapeTensor[0])\n",
    "    return (value: out, pullback: {v in (dPred, v)})\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "var preds = myModel(xTrainNormal, w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.002272\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(preds, yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients and backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "public class TensorWithGrad<Scalar: TensorFlowNumeric>{\n",
    "    var tensor: Tensor<Scalar>\n",
    "    var g: Tensor<Scalar>\n",
    "    \n",
    "    init (_ x: Tensor<Scalar>){\n",
    "        tensor = x\n",
    "        g = Tensor<Scalar>(zeros: tensor.shape)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "func myLin<Scalar: Numeric>(_ x: TensorWithGrad<Scalar>, _ w: TensorWithGrad<Scalar>, _ b: TensorWithGrad<Scalar>) -> TensorWithGrad<Scalar>{\n",
    "    return TensorWithGrad(matmul(x.tensor, w.tensor) + b.tensor)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "func myRelu<Scalar: Numeric & Comparable>(_ x: TensorWithGrad<Scalar>) -> TensorWithGrad<Scalar> {\n",
    "    return TensorWithGrad(max(0, x.tensor))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "func myMse(_ pred: TensorWithGrad<Float>, _ target: Tensor<Float>)->Tensor<Float>{\n",
    "    return (pred.tensor.squeezingShape(at: -1) - target).squared().mean()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "func mseGrad<Scalar: Numeric & Comparable>(_ inp: TensorWithGrad<Scalar>, _ target: TensorWithGrad<Scalar>){\n",
    "    inp.g = 2 * (inp.tensor.squeezingShape(at: -1) - target.tensor).expandingShape(at: -1) / Tensor<Scalar>(inp.tensor.scalarCountTensor)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "func reluGrad<Scalar: Numeric & Comparable>(_ inp: TensorWithGrad<Scalar>, _ out: TensorWithGrad<Scalar>){\n",
    "    inp.g = Tensor<Scalar>(inp.tensor .> 0) * out.g\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "func linGrad<Scalar: Numeric & Comparable>(_ inp: TensorWithGrad<Scalar>,\n",
    "                                           _ out: TensorWithGrad<Scalar>,\n",
    "                                           _ w: TensorWithGrad<Scalar>,\n",
    "                                           _ b: TensorWithGrad<Scalar>){\n",
    "    inp.g = matmul(out.g, w.tensor.transposed())\n",
    "    w.g = matmul(inp.tensor.transposed(), out.g)\n",
    "    b.g = out.g.sum(squeezingAxes: 0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "var inpt = TensorWithGrad(xTrainNormal)\n",
    "var w1t = TensorWithGrad(w1)\n",
    "var b1t = TensorWithGrad(b1)\n",
    "var w2t = TensorWithGrad(w2)\n",
    "var b2t = TensorWithGrad(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "func forwardBackward(_ inp: TensorWithGrad<Float>, _ target: Tensor<Float>) -> Tensor<Float> {\n",
    "    //forward pass\n",
    "    let l1 = myLin(inp, w1t, b1t)\n",
    "    let l2 = myRelu(l1)\n",
    "    let out = myLin(l2, w2t, b2t)\n",
    "    let loss = myMse(out, target)\n",
    "    \n",
    "    //backward pass\n",
    "    mseGrad(out, TensorWithGrad(target))\n",
    "    linGrad(l2, out, w2t, b2t)\n",
    "    reluGrad(l1, l2)\n",
    "    linGrad(inp, l1, w1t, b1t)\n",
    "    return loss\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "var loss = forwardBackward(inpt, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.002272\n"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And forward and backward a different way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "func forwardBackward<Scalar: TensorFlowFloatingPoint>(\n",
    "       _ x: Tensor<Scalar>, _ y: Tensor<Scalar>,\n",
    "       _ wt1: Tensor<Scalar>, _ bias1: Tensor<Scalar>,\n",
    "       _ wt2: Tensor<Scalar>, _ bias2: Tensor<Scalar>\n",
    ") -> (Tensor<Scalar>, Tensor<Scalar>, Tensor<Scalar>, Tensor<Scalar>, Tensor<Scalar>) {\n",
    "//     print(\"starting forward\")\n",
    "    let (l1, l1Pb) = valueWithPullback(at: x, wt1, bias1, in: linear)\n",
    "    let (l2, l2Pb) = valueWithPullback(at: l1, in: relu)\n",
    "    let (preds, l3Pb) = valueWithPullback(at: l2, wt2, bias2, in: linear)\n",
    "    let (loss, msePb) = valueWithPullback(at: preds, y, in: mse)\n",
    "//     print(\"done w forward\")\n",
    "    \n",
    "//     print(\"starting backprop\")\n",
    "    let (dPred, _ ) = msePb(Tensor<Scalar>([0.0]))\n",
    "    let (dL2, dWt2, dBias2) = l3Pb(dPred)\n",
    "    let (dL1) = l2Pb(dL2)\n",
    "    let (dInput, dWt1, dBias1) = l1Pb(dL1)\n",
    "//     print(\"done with backprop\")\n",
    "    \n",
    "    return (loss, dWt1, dBias1, dWt2, dBias2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var (loss2, dWt1, dBias1, dWt2, dBias2) = forwardBackward(xTrainNormal, yTrain, w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.002272\n"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure they agree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\n"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2 == loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\n"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dWt1 == w1t.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\n"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dBias1 == b1t.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\n"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dWt2 == w2t.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\n"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dBias2 == b2t.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
